app:
  description: Adds examples to prompts
  icon: ðŸ¤–
  icon_background: '#FFEAD5'
  mode: chat
  name: Add Examples To Prompt
  use_icon_as_answer_icon: false
kind: app
model_config:
  agent_mode:
    enabled: false
    max_iteration: 5
    strategy: react
    tools: []
  annotation_reply:
    enabled: false
  chat_prompt_config: {}
  completion_prompt_config: {}
  dataset_configs:
    datasets:
      datasets: []
    reranking_enable: false
    retrieval_model: multiple
    top_k: 4
  dataset_query_variable: ''
  external_data_tools: []
  file_upload:
    allowed_file_extensions:
    - .JPG
    - .JPEG
    - .PNG
    - .GIF
    - .WEBP
    - .SVG
    - .MP4
    - .MOV
    - .MPEG
    - .MPGA
    allowed_file_types: []
    allowed_file_upload_methods:
    - remote_url
    - local_file
    enabled: false
    image:
      detail: high
      enabled: false
      number_limits: 3
      transfer_methods:
      - remote_url
      - local_file
    number_limits: 3
  model:
    completion_params:
      stop: []
    mode: chat
    name: deepseek/deepseek-chat
    provider: openrouter
  more_like_this:
    enabled: false
  opening_statement: ''
  pre_prompt: "Your purpose is to act as a helpful assistant to the user By adding\
    \ useful examples to their prompts. You can expect that at the start of the chat,\
    \ the user will provide a large language model prompt that they have written,\
    \ but which does not contain an example. \n\n\nAt a minimum, you should add one\
    \ example to the prompt. If you think that adding more examples would increase\
    \ the accuracy of the outputs notably, then you should add multiple examples.\
    \ \n\n\nIn generating the examples to include in the prompt, you should do so\
    \ based upon your understanding of the objective of the prompt and your understanding\
    \ of best practices in providing examples to large language models. \n\n\nYour\
    \ purpose is solely to return the prompt from the user with the example or examples\
    \ that you recommend adding. Enclose your reformatted prompt with the examples\
    \ within a code fence so that the user can copy it out, especially if it contains\
    \ included code elements. If there are code elements in the reformatted prompt,\
    \ they should be enclosed within backticks to separate them from the body text.\
    \ \n\n\nExpect that the user may wish to engage in an iterative process by which,\
    \ after you improve one prompt, they send another and ask you to improve it. If\
    \ the user employs this methodology, then each prompt should be evaluated as a\
    \ new workflow. Prior prompts, you'd not set the context for future formatting\
    \ processes. "
  prompt_type: simple
  retriever_resource:
    enabled: true
  sensitive_word_avoidance:
    configs: []
    enabled: false
    type: ''
  speech_to_text:
    enabled: true
  suggested_questions: []
  suggested_questions_after_answer:
    enabled: false
  text_to_speech:
    enabled: true
  user_input_form: []
version: 0.1.5
